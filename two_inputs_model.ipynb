{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f23e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "import itertools\n",
    "import cv2 #image operations\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Display\n",
    "#from IPython.display import Image, display\n",
    "from PIL import Image\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import img_to_array, load_img, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get files from .env file\n",
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c32318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define repetitive values\n",
    "raw_dir = config['RAW_PATH']\n",
    "\n",
    "img_dim = int(config['DIM'])\n",
    "batch_size = int(config['BATCH_SIZE'])\n",
    "epoch_nbr = int(config['EPOCH'])\n",
    "\n",
    "input_shape = (img_dim, img_dim, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976aeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath where all of our images are stored\n",
    "original_data_path = raw_dir+'/dataset/Original' \n",
    "segmented_data_path =raw_dir+'/dataset/Segmented'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"Benign\", \"Early\", \"Pre\", \"Pro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473bd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the validation and training data separately\n",
    "def plot_loss_curves(history , metric , val_metric):\n",
    "  \"\"\"\n",
    "  Returns separate loss curves for training and validation metrics.\n",
    "  \"\"\" \n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history[metric]\n",
    "  val_accuracy = history.history[val_metric]\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  # Plot accuracy\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image data generator for train, val and test datasets\n",
    "# data augmentation is applied on the traing dataset\n",
    "\n",
    "def image_data_generator(preprocessing_fn = None):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        rotation_range = 20,\n",
    "        horizontal_flip = True,\n",
    "        preprocessing_function = preprocessing_fn,\n",
    "        shear_range=0.2, # shear the image\n",
    "        zoom_range=0.2, # zoom into the image\n",
    "        width_shift_range=0.2, # shift the image width ways\n",
    "        height_shift_range=0.2, # shift the image height ways\n",
    "    )\n",
    "    \n",
    "    validation_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255, \n",
    "        preprocessing_function = preprocessing_fn\n",
    "    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255, \n",
    "        preprocessing_function = preprocessing_fn\n",
    "    )\n",
    "    \n",
    "    return [train_datagen, validation_datagen, test_datagen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdec510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_dataset (data_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category_pos in [0,1,2,3]:\n",
    "        path = os.path.join(data_path, CATEGORIES[category_pos])\n",
    "        for img in os.listdir(path):\n",
    "            img_path = os.path.join(path, img)\n",
    "            image = load_img(img_path, target_size=(224, 224))\n",
    "            image = img_to_array(image)\n",
    "            data.append(image)\n",
    "            labels.append(category_pos)\n",
    "\n",
    "    data = np.array(data, dtype=\"float32\")\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    (training_x, test_x, training_y, test_y) = train_test_split(data, labels,\n",
    "                                                      test_size=0.20,\n",
    "                                                      random_state=42)\n",
    "    (train_x, val_x, train_y, val_y) = train_test_split(training_x, training_y,\n",
    "                                                      test_size=0.20,\n",
    "                                                      random_state=42)\n",
    "    \n",
    "    return [train_x, train_y, val_x, val_y, test_x, test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb796970",
   "metadata": {},
   "outputs": [],
   "source": [
    "[org_train_x, org_train_y, org_val_x, org_val_y, org_test_x, org_test_y] = get_split_dataset(original_data_path)\n",
    "[seg_train_x, seg_train_y, seg_val_x, seg_val_y, seg_test_x, seg_test_y] = get_split_dataset(segmented_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffeda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data generators\n",
    "train_datagen, val_datagen, test_datagen = image_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d93cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model = keras.applications.DenseNet201(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=input_shape,\n",
    "    pooling=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db752783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By setting the trainable property of this model we created to False,\n",
    "# we prevented the weights in non-trainable layers from being updated. \n",
    "# Otherwise, what the model learned would be destroyed.\n",
    "densenet_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c8db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with training case\n",
    "# densenet_model.trainable = True\n",
    "# count = 0\n",
    "# for layer in densenet_model.layers:\n",
    "#     if 'conv5' in layer.name:\n",
    "#         count = count + 1\n",
    "#         layer.trainable = True\n",
    "#     else:\n",
    "#         layer.trainable = False\n",
    "\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add724ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = keras.initializers.he_normal(seed=32)\n",
    "\n",
    "seg_input = keras.Input(shape=input_shape)\n",
    "seg_model = densenet_model(inputs= seg_input)\n",
    "\n",
    "org_input = keras.Input(shape=input_shape)\n",
    "org_model = densenet_model(inputs= org_input)\n",
    "\n",
    "output = keras.layers.concatenate([org_model, seg_model])\n",
    "output = keras.layers.Flatten()(output)\n",
    "#batch normailzation\n",
    "output = keras.layers.BatchNormalization()(output)\n",
    "    \n",
    "#Fully-connected block 1\n",
    "output = keras.layers.Dense(units=32,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer=initializer,\n",
    "                             kernel_regularizer=keras.regularizers.l2(0.001)\n",
    "                            )(output)\n",
    "output = keras.layers.BatchNormalization()(output)\n",
    "output = keras.layers.LeakyReLU()(output)\n",
    "output = keras.layers.Dropout(0.2)(output)\n",
    "\n",
    "#Fully-connected block 2\n",
    "output = keras.layers.Dense(units=32,\n",
    "                             activation='relu',\n",
    "                             kernel_initializer=initializer,\n",
    "                             kernel_regularizer=keras.regularizers.l2(0.001)\n",
    "                            )(output)\n",
    "\n",
    "output = keras.layers.BatchNormalization()(output)\n",
    "output = keras.layers.ReLU()(output)\n",
    "\n",
    "#Classifier block\n",
    "output = keras.layers.Dense(units=4,\n",
    "                             kernel_initializer=initializer,\n",
    "                             activation='softmax'\n",
    "                            )(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_inputs_model_densenet201 = keras.models.Model(inputs=[org_input, seg_input], outputs=[output])\n",
    "two_inputs_model_densenet201.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_inputs_model_densenet201.compile(loss='binary_crossentropy',\n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b804b5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model_history = two_inputs_model_densenet201.fit(train_datagen.flow([org_train_x, seg_train_x], \n",
    "                                                                   org_train_y,\n",
    "                                                                   batch_size=32,\n",
    "                                                                   shuffle=True),\n",
    "                                                steps_per_epoch=len(org_train_x)//32,\n",
    "                                                 validation_data=val_datagen.flow([org_val_x, seg_val_x], \n",
    "                                                                                   org_val_y,\n",
    "                                                                                   batch_size=32),\n",
    "                                                validation_steps=len(org_val_x)//32,\n",
    "                                                epochs=100\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_history , 'accuracy' , 'val_accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = two_inputs_model_densenet201.predict(test_datagen.flow([org_test_x, seg_test_x], \n",
    "                                                                   org_test_y,\n",
    "                                                                   batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels =  org_test_y\n",
    "predicted_labels = np.argmax(pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b49a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_confusion_matrix(\n",
    "    correct_labels, \n",
    "    predicted_labels,\n",
    "    title = \"two inputs densenet201 model confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5533367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(correct_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff32eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save a model\n",
    "two_inputs_model_densenet201.save(\"saved_model/two_inputs_model.h5\")\n",
    "\n",
    "# Load in a model and evaluate it\n",
    "loaded_model = tf.keras.models.load_model(\"saved_model/two_inputs_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
